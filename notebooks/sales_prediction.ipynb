{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= '10'><b>Load the data</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
      "       'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
      "       'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
      "       'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
      "       'Promo2SinceYear', 'PromoInterval', 'Year', 'Month', 'Day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "# Load the merged cleaned data from Task 1\n",
    "data = pd.read_csv('C:/Users/User/Desktop/Week-4/notebooks/cleaned_data.csv') \n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= '10'><b>Convert Date to datetime</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "data['Weekday'] = data['Date'].dt.weekday\n",
    "data['Weekend'] = (data['Weekday'] >= 5).astype(int)  # 1 if weekend, 0 if weekday\n",
    "data['DayOfMonth'] = data['Date'].dt.day\n",
    "data['Is_Beginning_Month'] = (data['DayOfMonth'] <= 10).astype(int)\n",
    "data['Is_Mid_Month'] = ((data['DayOfMonth'] > 10) & (data['DayOfMonth'] <= 20)).astype(int)\n",
    "data['Is_End_Month'] = (data['DayOfMonth'] > 20).astype(int)\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "numeric_features = ['Open', 'Promo', 'CompetitionDistance', 'DayOfMonth', 'Weekday']\n",
    "categorical_features = ['Store', 'StateHoliday']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Store', 'DayOfWeek', 'Open', 'Promo', 'StateHoliday',\n",
      "       'CompetitionDistance', 'Year', 'Month', 'Day'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= '6'><b>Building Models with Sklearn Pipelines</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define features and target\n",
    "features = numeric_features + categorical_features\n",
    "X = data[features]\n",
    "y = data['Sales']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= '6'><b>Choosing a Loss Function</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse}, MAE: {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= '6'><b>Post Prediction Analysis</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "feature_names = numeric_features + list(pipeline.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, importances)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size= '6'><b>Serialize Models</font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import datetime\n",
    "\n",
    "# Get current timestamp\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "filename = f\"model_{timestamp}.pkl\"\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(pipeline, filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
